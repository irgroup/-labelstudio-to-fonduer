{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer labels to Fonduer\n",
    "\n",
    "In this example, we will transfer the labels we manually annotated in Label Studio to Fonduer to be used as gold labels for evaluation.\n",
    "\n",
    "\n",
    "> Before any labels are annotated, please ensure that the document representations in Fonduer and Label Studio are the same. Otherwise, the labels might not be transferable! See [example_document_converter](example_document_converter.md) for further information.\n",
    "\n",
    "\n",
    "## Fonduer setup:\n",
    "The way fonduer is set up might influence the ability to transfer labels between the systems. Therefore, Fonduer has to be configured so that it does not need to modify the documents.\n",
    "\n",
    "### Read export\n",
    "First, we start with reading the export from Label Studio. We can use some of the information from our export to configure our data model in fonduer later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"mails_sm\"\n",
    "conn_string = \"postgresql://postgres:postgres@127.0.0.1:5432/\"\n",
    "\n",
    "dataset_path = \"data/mails\"\n",
    "export_path = os.path.join(dataset_path, \"export.json\")\n",
    "documents_path = os.path.join(dataset_path, \"documents\")\n",
    "\n",
    "\n",
    "from LabelstudioToFonduer.to_fonduer import parse_export\n",
    "export = parse_export(export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the fonduer project\n",
    "After that, we create the project in fonduer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-17 12:07:26,581][INFO] fonduer.meta:49 - Setting logging directory to: data/mails/logs/2022-11-17_12-07-26\n",
      "[2022-11-17 12:07:26,582][INFO] fonduer.meta:135 - Connecting user:postgres to 127.0.0.1:5432/mails_sm\n",
      "[2022-11-17 12:07:26,657][INFO] fonduer.meta:162 - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "from LabelstudioToFonduer.fonduer_tools import save_create_project\n",
    "save_create_project(conn_string=conn_string, project_name=project_name)\n",
    "\n",
    "\n",
    "from fonduer import Meta, init_logging\n",
    "init_logging(log_dir=os.path.join(dataset_path, \"logs\"))\n",
    "session = Meta.init(conn_string + project_name).Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonduer might read the documents with the wrong encoding, which causes errors. To avoid this, a dedicated `HTMLDocPreprocessor` can be used. `LabelStudio_to_Fonduer` provides a slightly modified `HTMLDocPreprocessor` as a starting point named [My_HTMLDocPreprocessor](https://github.com/irgroup/labelstudio-to-fonduer/blob/main/src/LabelstudioToFonduer/document_processor.py). \n",
    "\n",
    "The processor can be imported like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LabelstudioToFonduer.document_processor import My_HTMLDocPreprocessor\n",
    "from fonduer.parser import Parser\n",
    "doc_preprocessor = My_HTMLDocPreprocessor(documents_path, max_docs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup lingual parser\n",
    "By default, Fonduer uses a lingual parser that splits sentences based on the [SpaCy](https://spacy.io/) `split_sentences` function. While this method generally performs quite well, it does not handle abbreviations and special punctuation well.\n",
    "\n",
    "If our labels contain punctuations or abbreviations, we need to use a modified `lingual_parser`.\n",
    "`LabelStudio_to_Fonduer` comes with a modified version that splits sentences only on the `.` char and can handle given exceptions. \n",
    "To add exceptions and use this `ModifiedSpacyParser`, we can use this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LabelstudioToFonduer.lingual_parser import ModifiedSpacyParser\n",
    "exceptions = [\".NET\", \"Sr.\", \".WEB\", \".de\", \"Jr.\", \"Inc.\", \"Senior.\", \"p.\", \"m.\"]\n",
    "my_parser = ModifiedSpacyParser(lang=\"en\", split_exceptions=exceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import documents\n",
    "If the pipeline is set up, we can import our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-17 12:08:40,144][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0558b99ffb894af3b5c02956622f2a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_parser = Parser(session, \n",
    "    lingual_parser=my_parser, \n",
    "    structural=True, \n",
    "    lingual=True, \n",
    "    flatten=[])\n",
    "    \n",
    "corpus_parser.apply(doc_preprocessor, parallelism=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 10\n",
      "Sentences: 1336\n"
     ]
    }
   ],
   "source": [
    "from fonduer.parser.models import Document, Sentence\n",
    "\n",
    "print(f\"Documents: {session.query(Document).count()}\")\n",
    "print(f\"Sentences: {session.query(Sentence).count()}\")\n",
    "\n",
    "docs = session.query(Document).order_by(Document.name).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Fonduer data model\n",
    "In this step, the data model is created and then used to create the labeling functions and so on. For further information, please refer to the Fonduer documentation.\n",
    "\n",
    "As we already have some labeled data, we can derive some starting values to create the Fonduer data model. This configuration is highly dependent on the data we have.\n",
    "\n",
    "\n",
    "It might be beneficial to test the pipeline in advance to make sure Fonduer does not change any document and all annotated spans can be detected. Therefore, we will not spend too much time in setting up labeling functions and only rudimentarily set up some Fonduer processing for now. After we ensure that the pipeline works for our data, we will come back to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-17 12:08:48,140][INFO] fonduer.candidates.mentions:467 - Clearing table: title\n",
      "[2022-11-17 12:08:48,161][INFO] fonduer.candidates.mentions:467 - Clearing table: date\n",
      "[2022-11-17 12:08:48,163][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ff9254b08249dbbd3ee5ce17c0cb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-17 12:08:50,906][INFO] fonduer.candidates.candidates:138 - Clearing table title_date (split 0)\n",
      "[2022-11-17 12:08:50,919][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Mentions: 24 (15 titles, 9 dates)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6585b651935f4afcbb6f5667de54a6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fonduer.candidates.models import mention_subclass\n",
    "Title = mention_subclass(\"Title\")\n",
    "Date = mention_subclass(\"Date\")\n",
    "\n",
    "\n",
    "from fonduer.candidates import MentionNgrams\n",
    "title_ngrams = MentionNgrams(n_max=export.ngrams(\"Title\")[1] + 5, n_min=export.ngrams(\"Title\")[0])\n",
    "date_ngrams = MentionNgrams(n_max=export.ngrams(\"Date\")[1] + 5, n_min=export.ngrams(\"Date\")[0])\n",
    "\n",
    "\n",
    "from fonduer.candidates.matchers import LambdaFunctionMatcher\n",
    "title = export.lable_entitis(\"Title\")\n",
    "date = export.lable_entitis(\"Date\")\n",
    "\n",
    "\n",
    "def is_title(mention):\n",
    "    if mention.get_span() in title:\n",
    "        return True\n",
    "    else:\n",
    "        False\n",
    "\n",
    "\n",
    "def is_date(mention):\n",
    "    if mention.get_span() in date:\n",
    "        return True\n",
    "    else:\n",
    "        False\n",
    "\n",
    "\n",
    "title_matcher = LambdaFunctionMatcher(func=is_title)\n",
    "date_matcher = LambdaFunctionMatcher(func=is_date)\n",
    "\n",
    "\n",
    "from fonduer.candidates import MentionExtractor\n",
    "mention_extractor = MentionExtractor(\n",
    "    session,\n",
    "    [Title, Date],\n",
    "    [title_ngrams, date_ngrams],\n",
    "    [title_matcher, date_matcher],\n",
    ")\n",
    "\n",
    "\n",
    "from fonduer.candidates.models import Mention\n",
    "mention_extractor.apply(docs)\n",
    "num_title = session.query(Title).count()\n",
    "num_date = session.query(Date).count()\n",
    "\n",
    "print(f\"Total Mentions: {session.query(Mention).count()} ({num_title} titles, {num_date} dates)\")\n",
    "\n",
    "\n",
    "from fonduer.candidates.models import candidate_subclass\n",
    "TitleDate = candidate_subclass(\"TitleDate\", [Title, Date])\n",
    "\n",
    "\n",
    "from fonduer.candidates import CandidateExtractor\n",
    "candidate_extractor = CandidateExtractor(session, [TitleDate])\n",
    "candidate_extractor.apply(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load gold label\n",
    "To use our gold data in fonduer, it is finally time to transfer the labels from Label Studio to Fonduer.\n",
    "\n",
    "Therefore we create a `converter` entity from `LabelStudioToFonduer` based on our parsed export and the fonduer session.\n",
    "\n",
    "Then we use the `is_gold` function of our converter as a labeling function in the Fonduer Labeler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-11-17 12:08:54,374][INFO] fonduer.supervision.labeler:330 - Clearing Labels (split ALL)\n",
      "/usr/local/lib/python3.7/site-packages/fonduer/supervision/labeler.py:340: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  query = self.session.query(table).filter(table.candidate_id.in_(sub_query))\n",
      "[2022-11-17 12:08:54,379][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9375b6086dd424eaf837d00e0cbb971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from LabelstudioToFonduer.to_fonduer import ToFonduer\n",
    "converter = ToFonduer(label_studio_export=export, fonduer_session=session)\n",
    "\n",
    "\n",
    "from fonduer.supervision.models import GoldLabel\n",
    "from fonduer.supervision import Labeler\n",
    "labeler = Labeler(session, [TitleDate])\n",
    "\n",
    "labeler.apply(\n",
    "    docs=docs,\n",
    "    lfs=[[converter.is_gold]],\n",
    "    table=GoldLabel,\n",
    "    train=True,\n",
    "    parallelism=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if we were successful, we can count the transferred labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold labels found: 9 from 9\n",
      "Documents successfully transfered:\n",
      "file_0\n",
      "file_1\n",
      "file_2\n",
      "file_3\n",
      "file_4\n",
      "file_5\n",
      "file_6\n",
      "file_7\n",
      "file_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/fonduer/candidates/candidates.py:201: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  .filter(candidate_class.id.in_(sub_query))\n"
     ]
    }
   ],
   "source": [
    "train_cands = candidate_extractor.get_candidates()\n",
    "all_gold = labeler.get_gold_labels(train_cands)\n",
    "\n",
    "\n",
    "print(\"Gold labels found:\", all_gold[0].sum(), \"from\", len(export.documents))\n",
    "print(\"Documents successfully transfered:\")\n",
    "\n",
    "golds = []\n",
    "for k, v in zip(all_gold[0], train_cands[0]):\n",
    "    if k:\n",
    "        golds.append(v)\n",
    "        print(v.document.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
